services:
  hive-metastore-db:
    image: postgres:16-bullseye
    container_name: hive-metastore-db
    hostname: hive-metastore-db
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "psql", "-U", "hive", "metastoredb"]
      interval: 5s
      retries: 5
    restart: always
    ports:
      - 5432:5432     
    networks:
        - likehouse_network
    
  hive-metastore:
    build:
      context: ./hive-metastore
    container_name: hive-metastore
    hostname: hive-metastore
    entrypoint: /entrypoint.sh
    ports:
      - 9083:9083
    volumes:
      - ./hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    env_file:
      - .env
    depends_on:
      - hive-metastore-db
    networks:
      - likehouse_network

  kyuubi:
    hostname: kyuubi
    container_name: kyuubi
    image: apache/kyuubi:1.7.0-spark
    volumes:
      - ./kyuubi/kyuubi-defaults.conf:/opt/kyuubi/conf/kyuubi-defaults.conf
    ports:
      - 10009:10009
      - 10099:10099
    restart: always
    depends_on:
      - spark-master
    networks:
      - likehouse_network

  spark-master:
    build:
      context: ./spark
    container_name: spark-master
    hostname: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - 7077:7077
      - 8081:8080
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - likehouse_network

  spark-worker:
    image: bitnami/spark:3.3.2
    container_name: spark-worker
    hostname: spark-worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    env_file:
      - .env
    depends_on:
      - spark-master
    networks:
      - likehouse_network
  
  pyspark-jupyter-notebook:
    build:
      context: ./jupyter
    container_name: pyspark-jupyter-notebook
    env_file:
      - .env
    volumes:
      - ./jupyter/work:/home/jovyan/work
    ports:
      - 10001:8888
    restart: always 
    networks:
      - likehouse_network
  
  dbt-spark:
    build:
      context: ./airflow/dags/silver
    container_name: dbt-spark
    env_file:
      - .env
    volumes:
      - ./airflow/dags/silver:/usr/app/dbt
    networks:
      - likehouse_network

networks:
  likehouse_network:
    external: true